{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6129695f",
   "metadata": {},
   "source": [
    "# UNION (single-channel) — policy distillation to CNet192\n",
    "\n",
    "This notebook distills an **ensemble of CNet192 teachers**  into a **single CNet192** student;\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e244ba8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEVICE: cuda  AMP: True\n"
     ]
    }
   ],
   "source": [
    "# --- Imports / setup ---\n",
    "import os, time, math, random\n",
    "from pathlib import Path\n",
    "from typing import Any, Dict, List, Tuple, Optional\n",
    "from PPO.ppo_hall_of_fame import PPOHallOfFame\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm.auto import tqdm\n",
    "from C4.CNet192 import CNet192, load_cnet192, save_cnet192\n",
    "from C4.fast_connect4_lookahead import Connect4Lookahead\n",
    "from C4.connect4_env import Connect4Env\n",
    "\n",
    "SEED = 666\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "USE_AMP = (DEVICE.type == \"cuda\")\n",
    "print(\"DEVICE:\", DEVICE, \" AMP:\", USE_AMP)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "893d0056-d3fd-4f9e-a3b9-3e11fd25d0d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPISODES     = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "43ced837-1d8d-4e6e-93a6-22e639ea779f",
   "metadata": {},
   "outputs": [],
   "source": [
    "HOF_METASCORES = {\n",
    "    \"PPO_Models/MIX_9.pt\": 0.758167,\n",
    "    \"PPO_Models/MIX_1.pt\": 0.517667,\n",
    "    \"PPO_Models/MIX_8b.pt\": 0.517500,\n",
    "    \"PPO_Models/MIX_7.pt\": 0.515833,\n",
    "    \"PPO_Models/MIX_5.pt\": 0.443333,\n",
    "    \"PPO_Models/MIX_8a.pt\": 0.381833,\n",
    "    \"PPO_Models/MIX_6.pt\": 0.365667,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e8346c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Inputs: teacher ensemble weights (meta-scores) ---\n",
    "\n",
    "# Distillation data config\n",
    "N_DISTILL_POSITIONS = 120_000          # base samples before symmetry augmentation\n",
    "MAX_RANDOM_PLIES = 18        # random plies from empty board (position diversity knob)\n",
    "ADD_HFLIP = True             # symmetry augmentation (recommended)\n",
    "\n",
    "# Teacher voting config\n",
    "N_ACTIONS = 7\n",
    "TEACHER_TEMP = 1.0           # temperature used for argmax voting (kept for compatibility)\n",
    "# If you ever want soft targets instead of vote targets, you can add it, but UNION uses votes.\n",
    "\n",
    "# Mentor (lookahead) override config (kept small for speed)\n",
    "USE_MENTOR = True\n",
    "MENTOR_DEPTH = 9\n",
    "MENTOR_PROB = 0.99           # apply mentor on ~6% of generated samples\n",
    "MENTOR_COEF = 0.40           # blend: (1-COEF)*vote + COEF*mentor_onehot\n",
    "MENTOR_MIN_CONF = 0.70       # only mentor if vote-top probability < this\n",
    "\n",
    "# Student training config\n",
    "LR = 1.0e-4\n",
    "WEIGHT_DECAY = 5e-5\n",
    "EPOCHS = 64\n",
    "BATCH_SIZE = 512\n",
    "NUM_WORKERS = 0              # set >0 if you like (Windows often prefers 0)\n",
    "GRAD_CLIP = 1.0\n",
    "TEMPERATURE = 1.0           # logits / temp before softmax in loss\n",
    "\n",
    "# Output\n",
    "OUT_DIR = Path(\"PPO_Models\")\n",
    "OUT_TAG = \"UNION_3\"\n",
    "\n",
    "# Output filenames (configured here, not hidden later)\n",
    "OUT_FILE = f\"{OUT_TAG}.pt\"\n",
    "OUT_PATH = OUT_DIR / OUT_FILE\n",
    "OUT_LATEST_PATH = OUT_DIR / f\"{OUT_TAG}_LATEST.pt\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "175d529c-6864-4fca-a59f-f9b3bac8e7d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92446d934880476f9bd6cdce01c5fe63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading teachers:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded teachers: ['MIX_9', 'MIX_1', 'MIX_8b', 'MIX_7', 'MIX_5', 'MIX_8a', 'MIX_6']\n",
      "Meta weights: {'MIX_9': 0.21661914885044098, 'MIX_1': 0.14790485799312592, 'MIX_8b': 0.14785714447498322, 'MIX_7': 0.14738085865974426, 'MIX_5': 0.1266665756702423, 'MIX_8a': 0.10909514129161835, 'MIX_6': 0.10447628051042557}\n"
     ]
    }
   ],
   "source": [
    "# --- Load teachers (CNet192 checkpoints) ---------------------------------\n",
    "TEACHER_PATHS = list(HOF_METASCORES.keys())\n",
    "TEACHER_NAMES = [Path(p).stem for p in TEACHER_PATHS]\n",
    "HOF_SPECS = dict(zip(TEACHER_NAMES, TEACHER_PATHS))\n",
    "\n",
    "hof = PPOHallOfFame(device=DEVICE)\n",
    "\n",
    "for name, path in HOF_SPECS.items():\n",
    "    hof.add_member(\n",
    "        name=name,\n",
    "        ckpt_path=path,\n",
    "        metascore=float(HOF_METASCORES[path]),\n",
    "    )\n",
    "\n",
    "# Load all POP members as frozen policies (wrapped)\n",
    "TEACHERS = {name: hof.ensure_loaded(name) for name in tqdm(TEACHER_NAMES, desc=\"Loading teachers\")}\n",
    "print(\"Loaded teachers:\", TEACHER_NAMES)\n",
    "\n",
    "# Normalized meta-score weights (used for majority-vote distillation)\n",
    "raw_weights = np.array([HOF_METASCORES[HOF_SPECS[n]] for n in TEACHER_NAMES], dtype=np.float32)\n",
    "raw_weights = np.maximum(raw_weights, 1e-9)\n",
    "META_WEIGHTS = raw_weights / raw_weights.sum()\n",
    "print(\"Meta weights:\", {n: float(w) for n, w in zip(TEACHER_NAMES, META_WEIGHTS)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3fc653fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNet192(\n",
       "  (conv1): Conv2d(1, 192, kernel_size=(4, 4), stride=(1, 1))\n",
       "  (conv_mid): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv2): Conv2d(192, 192, kernel_size=(2, 2), stride=(1, 1))\n",
       "  (fc): Linear(in_features=1152, out_features=192, bias=True)\n",
       "  (policy_fc): Linear(in_features=192, out_features=192, bias=True)\n",
       "  (policy_out): Linear(in_features=192, out_features=7, bias=True)\n",
       "  (value_fc): Linear(in_features=192, out_features=192, bias=True)\n",
       "  (value_out): Linear(in_features=192, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mentor (Numba/CPU)\n",
    "MENTOR = Connect4Lookahead() if USE_MENTOR else None\n",
    "\n",
    "# --- Student init ---------------------------------------------------------\n",
    "student = CNet192(in_channels=1, use_mid_3x3=True).to(DEVICE)\n",
    "student.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0840d030",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_majority_vote(\n",
    "    actions: List[int],\n",
    "    weights: np.ndarray,\n",
    "    n_actions: int,\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Score-weighted majority vote over teacher actions.\n",
    "\n",
    "    actions: list of ints (one per teacher)\n",
    "    weights: np.array of same length (meta-score weights)\n",
    "    \"\"\"\n",
    "    votes = np.zeros(n_actions, dtype=np.float32)\n",
    "    for a, w in zip(actions, weights):\n",
    "        if 0 <= int(a) < n_actions:\n",
    "            votes[int(a)] += float(w)\n",
    "\n",
    "    total = votes.sum()\n",
    "    return votes / total\n",
    "\n",
    "def mentor_override(\n",
    "    env: Connect4Env,\n",
    "    target_probs: np.ndarray,\n",
    "    legal_actions: List[int],\n",
    "    depth: int = 3,\n",
    "    max_strength: float = 0.35,\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Soft mentor:\n",
    "      - NEVER hard-overrides POP.\n",
    "      - Computes an effective lambda in [0, max_strength] based on:\n",
    "          * POP entropy (uncertainty)\n",
    "          * POP probability on mentor's move\n",
    "      - Then nudges target_probs toward mentor's move via convex combination.\n",
    "\n",
    "      new_p = (1 - λ) * POP + λ * one_hot(a_mentor)\n",
    "    \"\"\"\n",
    "    if not legal_actions: return target_probs\n",
    "\n",
    "    p = np.asarray(target_probs, dtype=np.float32)\n",
    "    if p.shape[0] != N_ACTIONS: return target_probs\n",
    "\n",
    "    # Ask mentor for best move for current mover\n",
    "    try:\n",
    "        a_mentor = MENTOR.n_step_lookahead(env.board, player=env.current_player, depth=depth,)\n",
    "    except Exception: return p\n",
    "\n",
    "    if a_mentor not in legal_actions: return p\n",
    "\n",
    "    # --- POP confidence: high entropy -> low confidence, low entropy -> high confidence\n",
    "    eps = 1e-8\n",
    "    p_clipped = np.clip(p, eps, 1.0)\n",
    "    entropy = -float(np.sum(p_clipped * np.log(p_clipped)))\n",
    "    max_entropy = math.log(len(p))\n",
    "    conf_pop = 1.0 - entropy / max_entropy  # 0 = very unsure, 1 = very sure\n",
    "\n",
    "    # POP's belief in mentor move\n",
    "    p_mentor_pop = float(p[a_mentor])\n",
    "\n",
    "    # Mentor strongest when:\n",
    "    #   - POP is uncertain (low conf_pop)\n",
    "    #   - POP doesn't already like mentor move (low p_mentor_pop)\n",
    "    lambda_eff = max_strength * (1.0 - conf_pop) * (1.0 - p_mentor_pop)\n",
    "\n",
    "    if lambda_eff <= 0.0:\n",
    "        return p\n",
    "\n",
    "    # Convex combo: gently push mass toward mentor move\n",
    "    one_hot = np.zeros_like(p)\n",
    "    one_hot[a_mentor] = 1.0\n",
    "\n",
    "    new_p = (1.0 - lambda_eff) * p + lambda_eff * one_hot\n",
    "    new_p = np.clip(new_p, 1e-6, 1.0)\n",
    "    new_p /= new_p.sum()\n",
    "    return new_p\n",
    "\n",
    "\n",
    "class DistillDataset(Dataset):\n",
    "    \"\"\"\n",
    "    (state, target_probs) dataset for offline policy distillation.\n",
    "\n",
    "    states:  (N, C, 6, 7) float32  — C is 4 or 6 in your setup\n",
    "    targets: (N, N_ACTIONS) float32 — probability distribution over columns\n",
    "    \"\"\"\n",
    "    def __init__(self, states: np.ndarray, targets: np.ndarray):\n",
    "        assert states.ndim == 4 and states.shape[-2:] == (6, 7), \\\n",
    "            f\"states shape should be (N, C, 6, 7), got {states.shape}\"\n",
    "        assert targets.ndim == 2 and targets.shape[1] == N_ACTIONS, \\\n",
    "            f\"targets shape should be (N, {N_ACTIONS}), got {targets.shape}\"\n",
    "\n",
    "        self.states = states.astype(np.float32)\n",
    "        self.targets = targets.astype(np.float32)\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return self.states.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        x = torch.from_numpy(self.states[idx])   # (C, 6, 7)\n",
    "        y = torch.from_numpy(self.targets[idx])  # (7,)\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4656caac-eb30-4a04-a63a-b0c1816e40b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Teacher forward helpers (HOF-wrapped CNet192 / ensemble) ------------\n",
    "\n",
    "def _module_device(m: torch.nn.Module) -> torch.device:\n",
    "    try:\n",
    "        return next(m.parameters()).device\n",
    "    except StopIteration:\n",
    "        return DEVICE  # fallback\n",
    "\n",
    "def _state_to_1ch_batch(state: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Normalize numpy state to (B,1,6,7) float32.\n",
    "    Accepts: (6,7), (1,6,7), (2,6,7), (B,6,7), (B,1,6,7), (B,2,6,7)\n",
    "    \"\"\"\n",
    "    s = np.asarray(state)\n",
    "\n",
    "    if s.ndim == 2:  # (6,7)\n",
    "        return s.astype(np.float32)[None, None, :, :]\n",
    "\n",
    "    if s.ndim == 3:\n",
    "        # (1,6,7) or (2,6,7) or (C,6,7) OR (B,6,7)\n",
    "        if s.shape[-2:] != (6, 7):\n",
    "            raise ValueError(f\"Bad state shape: {s.shape}\")\n",
    "\n",
    "        C0 = int(s.shape[0])\n",
    "\n",
    "        # channel-first single sample\n",
    "        if C0 in (1, 2, 4, 6) and s.shape[1:] == (6, 7):\n",
    "            if C0 == 1:\n",
    "                return s.astype(np.float32)[None, :, :, :]  # (1,1,6,7)\n",
    "            # use first two planes as (me - opp) -> POV scalar\n",
    "            scalar = (s[0] - s[1]).astype(np.float32)\n",
    "            return scalar[None, None, :, :]\n",
    "\n",
    "        # otherwise treat as batch: (B,6,7)\n",
    "        return s.astype(np.float32)[:, None, :, :]\n",
    "\n",
    "    if s.ndim == 4:\n",
    "        # (B,C,6,7)\n",
    "        if s.shape[-2:] != (6, 7):\n",
    "            raise ValueError(f\"Bad state shape: {s.shape}\")\n",
    "        C = int(s.shape[1])\n",
    "        if C == 1:\n",
    "            return s.astype(np.float32)\n",
    "        # (me,opp,...) -> POV scalar\n",
    "        scalar = (s[:, 0] - s[:, 1]).astype(np.float32)\n",
    "        return scalar[:, None, :, :]\n",
    "\n",
    "    raise ValueError(f\"Unsupported state shape: {s.shape}\")\n",
    "\n",
    "@torch.inference_mode()\n",
    "def _logits_np(policy: torch.nn.Module, s_1ch: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    policy: HOF-wrapped CNet192 policy (or ensemble_teacher)\n",
    "    s_1ch : state from env.get_state(), typically (1,6,7) float32 POV\n",
    "    returns: (7,) numpy logits\n",
    "    \"\"\"\n",
    "    dev = _module_device(policy)\n",
    "\n",
    "    x_np = np.ascontiguousarray(_state_to_1ch_batch(s_1ch), dtype=np.float32)  # (1,1,6,7)\n",
    "    x = torch.from_numpy(x_np).to(dev)\n",
    "\n",
    "    out = policy.forward(x)\n",
    "    if isinstance(out, (tuple, list)):\n",
    "        logits = out[0]\n",
    "    else:\n",
    "        logits = out\n",
    "\n",
    "    return logits[0].detach().float().cpu().numpy()\n",
    "\n",
    "def _argmax_legal_center_tiebreak(\n",
    "    logits,\n",
    "    legal: List[int],\n",
    "    center: int = 3,\n",
    "    tol: float = 1e-12,\n",
    ") -> int:\n",
    "    \"\"\"Deterministic argmax over legal actions; ties prefer center, then smaller index.\"\"\"\n",
    "    if not legal:\n",
    "        raise ValueError(\"No legal actions\")\n",
    "\n",
    "    # accept torch or numpy\n",
    "    if isinstance(logits, torch.Tensor):\n",
    "        vals = logits.detach().float().cpu().numpy().astype(np.float64, copy=False)\n",
    "    else:\n",
    "        vals = np.asarray(logits, dtype=np.float64)\n",
    "\n",
    "    best = max(vals[c] for c in legal)\n",
    "\n",
    "    tied = [c for c in legal if abs(vals[c] - best) <= tol]\n",
    "    if len(tied) == 1:\n",
    "        return int(tied[0])\n",
    "\n",
    "    return int(min(tied, key=lambda c: (abs(c - center), c)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "81ae8fba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31ff89f5c41341f5bfff34b3aef76b6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating POP rollouts:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final distill dataset: states (31000, 1, 6, 7), targets (31000, 7)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "31000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate distillation dataset from POP \n",
    "\n",
    "def generate_distill_data(\n",
    "    n_episodes: int = 200,\n",
    "    max_moves: int = 42,\n",
    "    max_samples: int = 80_000,\n",
    "    seed: int = 666,\n",
    "    use_mentor: bool = True,\n",
    "    mentor_depth: int = 3,\n",
    ") -> DistillDataset:\n",
    "    \"\"\"\n",
    "    Let the POP ensemble play games in Connect4Env and record:\n",
    "      - s_t  := env.get_state(perspective=env.current_player)\n",
    "      - y_t  := score-weighted majority vote over teacher greedy actions\n",
    "\n",
    "    Progress:\n",
    "      - Outer loop is wrapped in tqdm so you see episode progress.\n",
    "    \"\"\"\n",
    "\n",
    "    rng = np.random.default_rng(seed)\n",
    "    import random as _random\n",
    "    _random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "    states: List[np.ndarray] = []\n",
    "    targets: List[np.ndarray] = []\n",
    "\n",
    "    total_samples = 0\n",
    "\n",
    "    for ep in tqdm(range(n_episodes), desc=\"Generating POP rollouts\"):\n",
    "        env = Connect4Env()\n",
    "        env.reset()\n",
    "        done = False\n",
    "        moves = 0\n",
    "\n",
    "        while (not done) and moves < max_moves and total_samples < max_samples:\n",
    "            legal = env.available_actions()\n",
    "            if not legal:\n",
    "                break\n",
    "\n",
    "            # Mover-centric state; typically (4,6,7) in your setup\n",
    "            s = env.get_state(perspective=env.current_player)\n",
    "            s = np.asarray(s, dtype=np.float32)\n",
    "\n",
    "            # Each teacher proposes a greedy action\n",
    "            teacher_actions: List[int] = []\n",
    "            for name in TEACHER_NAMES:\n",
    "                policy = TEACHERS[name]\n",
    "                logits = _logits_np(policy, s)              # (7,)\n",
    "                a = _argmax_legal_center_tiebreak(logits, legal)\n",
    "                teacher_actions.append(int(a))\n",
    "\n",
    "            # Score-weighted majority vote\n",
    "            target_probs = weighted_majority_vote(\n",
    "                teacher_actions,\n",
    "                META_WEIGHTS,\n",
    "                n_actions=N_ACTIONS,\n",
    "            )\n",
    "\n",
    "            # Optional: mentor tweak / override\n",
    "            if use_mentor:\n",
    "                target_probs = mentor_override(\n",
    "                    env=env,\n",
    "                    target_probs=target_probs,\n",
    "                    legal_actions=legal,\n",
    "                    depth=MENTOR_DEPTH,\n",
    "                )\n",
    "\n",
    "            # Snapshot (state, label)\n",
    "            states.append(s)\n",
    "            targets.append(target_probs.astype(np.float32))\n",
    "            total_samples += 1\n",
    "\n",
    "            # Use POP majority action to drive env\n",
    "            majority_action = int(np.argmax(target_probs))\n",
    "            if majority_action not in legal:\n",
    "                majority_action = int(rng.choice(legal))\n",
    "\n",
    "            _, _, done = env.step(majority_action)\n",
    "            moves += 1\n",
    "\n",
    "        if total_samples >= max_samples:\n",
    "            break\n",
    "\n",
    "    states_arr = np.stack(states, axis=0)   # (N, C, 6, 7)\n",
    "    targets_arr = np.stack(targets, axis=0) # (N, 7)\n",
    "\n",
    "    print(f\"Final distill dataset: states {states_arr.shape}, targets {targets_arr.shape}\")\n",
    "    return DistillDataset(states_arr, targets_arr)\n",
    "\n",
    "\n",
    "# Kick off dataset generation\n",
    "distill_dataset = generate_distill_data(\n",
    "    n_episodes=EPISODES,\n",
    "    max_moves=42,\n",
    "    max_samples=100_000,\n",
    "    seed=666,\n",
    "    use_mentor=True,  \n",
    "    mentor_depth=MENTOR_DEPTH,\n",
    ")\n",
    "\n",
    "len(distill_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ee55edd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9f8b73a1e9b4d90b02ca32db7436422",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/64:   0%|          | 0/60 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1/64] distill_loss = 1.5827\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "873c3db22f2643d38d74381b683ab632",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2/64:   0%|          | 0/60 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 2/64] distill_loss = 0.9403\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a45f3395f0d149b2af1e7a18ca98839a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3/64:   0%|          | 0/60 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 3/64] distill_loss = 0.5117\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ced22caa36614212b6f4ec85b5050785",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4/64:   0%|          | 0/60 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 4/64] distill_loss = 0.2367\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4bee7745e16465c910c9ddbe6e42870",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5/64:   0%|          | 0/60 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 5/64] distill_loss = 0.0754\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6615cccd7944bd0a0daeb307619cd80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 6/64:   0%|          | 0/60 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 6/64] distill_loss = 0.0222\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78b3946a47c0426996268e956e2698f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 7/64:   0%|          | 0/60 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 7/64] distill_loss = 0.0148\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb4aefe4a9ef41be934895bc7ff96e04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 8/64:   0%|          | 0/60 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 8/64] distill_loss = 0.0121\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "177ce3c5ad2a461a8fa8b6580791531c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 9/64:   0%|          | 0/60 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 9/64] distill_loss = 0.0070\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0dd17df22b14bf4a36ac339830e2553",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 10/64:   0%|          | 0/60 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 10/64] distill_loss = 0.0071\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "138a47538d384eef92f034ccd14bddea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 11/64:   0%|          | 0/60 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 11/64] distill_loss = 0.0057\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebedfe422c064945b17d155d66e5986b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 12/64:   0%|          | 0/60 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 12/64] distill_loss = 0.0032\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e869a6f8f5c40aa97e7c5f8a97fec70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 13/64:   0%|          | 0/60 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 13/64] distill_loss = 0.0027\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9638fbcfe22f414886b911f48f796ba8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 14/64:   0%|          | 0/60 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 14/64] distill_loss = 0.0024\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "041e6c94990e428fac0b0077cbfcfacd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 15/64:   0%|          | 0/60 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 15/64] distill_loss = 0.0016\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49f88e21283749119a55f6743fdd519d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 16/64:   0%|          | 0/60 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 16/64] distill_loss = 0.0026\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33430dbc0c634331affc17b0ffe128f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 17/64:   0%|          | 0/60 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 17/64] distill_loss = 0.0018\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02678f261c9e4905be186ec340ad2cda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 18/64:   0%|          | 0/60 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 18/64] distill_loss = 0.0022\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "034cd269a5aa4eef96a8c62a6a0c0544",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 19/64:   0%|          | 0/60 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 19/64] distill_loss = 0.0016\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01c187059d9b484492e05e1aca4fe72f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 20/64:   0%|          | 0/60 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 20/64] distill_loss = 0.0034\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cfd0a4f59c24bbda46de588d5a06cb4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 21/64:   0%|          | 0/60 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 21/64] distill_loss = 0.0047\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6366d74b78084d3ba8d01fad8bd42244",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 22/64:   0%|          | 0/60 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 22/64] distill_loss = 0.0037\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3f6c9ef18ec45758eb37360f1c6df28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 23/64:   0%|          | 0/60 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 23/64] distill_loss = 0.0018\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b58b8e6070de4900bab29689afeeefa2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 24/64:   0%|          | 0/60 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 24/64] distill_loss = 0.0008\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4e18b8f348c48e09d971ea828e5956c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 25/64:   0%|          | 0/60 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 25/64] distill_loss = 0.0012\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da51b811cd6a4f158383ad733b977d31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 26/64:   0%|          | 0/60 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 26/64] distill_loss = 0.0005\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "925f04781a06403384a16dc9937dd6bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 27/64:   0%|          | 0/60 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 27/64] distill_loss = 0.0008\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "740fc8ad36f04315a7a8cbb2618fde76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 28/64:   0%|          | 0/60 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 28/64] distill_loss = 0.0010\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5035b15c883043178107995eab855af0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 29/64:   0%|          | 0/60 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 29/64] distill_loss = 0.0018\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5707df063e554b29b6ced381fb4811cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 30/64:   0%|          | 0/60 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 30/64] distill_loss = 0.0014\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5513f540504b45789ee48f402dc862b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 31/64:   0%|          | 0/60 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 31/64] distill_loss = 0.0005\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4072eb6d78fa4ceb8bd3798325d8976f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 32/64:   0%|          | 0/60 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 32/64] distill_loss = 0.0015\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "532c52acc6ed480a982f764b06f3ca71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 33/64:   0%|          | 0/60 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 33/64] distill_loss = 0.0013\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06fdc4964fdf46bdbad5df21d730b22a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 34/64:   0%|          | 0/60 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 34/64] distill_loss = 0.0012\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af66d8033ccd4a449652bb11b0a8bdd1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 35/64:   0%|          | 0/60 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 35/64] distill_loss = 0.0016\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e355774ed10e410bade272738e536a85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 36/64:   0%|          | 0/60 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 36/64] distill_loss = 0.0006\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bebeb71d3c824563a97f95fa897a06a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 37/64:   0%|          | 0/60 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 37/64] distill_loss = 0.0008\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f78c3de3017941568496cbdee2ea1bdd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 38/64:   0%|          | 0/60 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 38/64] distill_loss = 0.0013\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a1340ee454349d7a4f8946c03ec453b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 39/64:   0%|          | 0/60 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 39/64] distill_loss = 0.0012\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d6741cce63d476c914f65dea0c623cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 40/64:   0%|          | 0/60 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 40/64] distill_loss = 0.0010\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afcfe74afb45441fa77379473e4f6c4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 41/64:   0%|          | 0/60 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 41/64] distill_loss = 0.0013\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ef491f41da645f097a8636d7f18fb79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 42/64:   0%|          | 0/60 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 42/64] distill_loss = 0.0011\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "183eb0411e5b4e67a612da7216458b89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 43/64:   0%|          | 0/60 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 43/64] distill_loss = 0.0006\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "484223ca55904dc09960c05f7d8c6ad7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 44/64:   0%|          | 0/60 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 44/64] distill_loss = 0.0011\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6cd2293729b44356b620e217b2c766e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 45/64:   0%|          | 0/60 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 45/64] distill_loss = 0.0006\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a8f57a81c2746249d3a71877a9a89db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 46/64:   0%|          | 0/60 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 46/64] distill_loss = 0.0002\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c48b0322ce5464baad7472f5e479059",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 47/64:   0%|          | 0/60 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 47/64] distill_loss = 0.0003\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ea950b82fe141eab5f10cd1a6b541fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 48/64:   0%|          | 0/60 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 48/64] distill_loss = 0.0008\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09103c5ff13a4f35b4e37feb27b5ad98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 49/64:   0%|          | 0/60 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 49/64] distill_loss = 0.0006\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "542797252c514fe1b72dea4677d89c95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 50/64:   0%|          | 0/60 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 50/64] distill_loss = 0.0008\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5589caf7b46043f3ba9884e78bd20541",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 51/64:   0%|          | 0/60 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 51/64] distill_loss = 0.0012\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fa5c01742f8487282edf639f28b6e04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 52/64:   0%|          | 0/60 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 52/64] distill_loss = 0.0013\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf221c2af63a462f915e7929e96975f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 53/64:   0%|          | 0/60 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 53/64] distill_loss = 0.0011\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5afd3cbf89c64660820c327d64406c30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 54/64:   0%|          | 0/60 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 54/64] distill_loss = 0.0012\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2620bfda53245babdfdb92ec64439dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 55/64:   0%|          | 0/60 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 55/64] distill_loss = 0.0006\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1323e8ec934451f94a02b5371a9c691",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 56/64:   0%|          | 0/60 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 56/64] distill_loss = 0.0002\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4012d609a0044a6e8eb012232e932e3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 57/64:   0%|          | 0/60 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 57/64] distill_loss = 0.0001\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0105803ab284d728fdfb6e563cfdd86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 58/64:   0%|          | 0/60 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 58/64] distill_loss = 0.0001\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2321b15623264f37bd3e9f7e0852b691",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 59/64:   0%|          | 0/60 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 59/64] distill_loss = 0.0001\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aab360288fb240c59f46c4ce01f96160",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 60/64:   0%|          | 0/60 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 60/64] distill_loss = 0.0003\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87913f6d422d48449699bf99f7d1e495",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 61/64:   0%|          | 0/60 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 61/64] distill_loss = 0.0009\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "963072873d824476b8f7eb687cd998ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 62/64:   0%|          | 0/60 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 62/64] distill_loss = 0.0022\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2243a042f08467abc41bbed98117657",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 63/64:   0%|          | 0/60 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 63/64] distill_loss = 0.0017\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fde9ed2ce76436a802f9a962c6e2722",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 64/64:   0%|          | 0/60 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 64/64] distill_loss = 0.0010\n"
     ]
    }
   ],
   "source": [
    "# Train student via POP distillation \n",
    "train_loader = DataLoader(distill_dataset, batch_size=BATCH_SIZE, shuffle=True, drop_last=True,)\n",
    "optimizer = torch.optim.Adam(student.parameters(), lr=LR)\n",
    "\n",
    "\n",
    "def distill_loss(\n",
    "    student_logits: torch.Tensor,\n",
    "    target_probs: torch.Tensor,\n",
    "    temperature: float = 1.0,\n",
    ") -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    KL(target || student) with optional temperature scaling on student logits.\n",
    "    \"\"\"\n",
    "    if temperature != 1.0:\n",
    "        student_logits = student_logits / temperature\n",
    "\n",
    "    log_student = F.log_softmax(student_logits, dim=-1)\n",
    "    loss = F.kl_div(log_student, target_probs, reduction=\"batchmean\")\n",
    "    return loss\n",
    "\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    student.train()\n",
    "    running_loss = 0.0\n",
    "    n_batches = 0\n",
    "\n",
    "    for x_batch, y_batch in tqdm(\n",
    "        train_loader,\n",
    "        desc=f\"Epoch {epoch}/{EPOCHS}\",\n",
    "        leave=False,\n",
    "    ):\n",
    "        # x_batch: (B, C, 6, 7), y_batch: (B, 7)\n",
    "        x_batch = x_batch.to(DEVICE)\n",
    "        y_batch = y_batch.to(DEVICE)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        logits, _ = student.forward(x_batch)\n",
    "        loss = distill_loss(logits, y_batch, temperature=TEMPERATURE)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(student.parameters(), max_norm=0.5)\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += float(loss.item())\n",
    "        n_batches += 1\n",
    "\n",
    "    avg_loss = running_loss / max(1, n_batches)\n",
    "    print(f\"[Epoch {epoch}/{EPOCHS}] distill_loss = {avg_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7f0c425b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: PPO_Models\\UNION_3.pt\n"
     ]
    }
   ],
   "source": [
    "# --- Save distilled student (CNet192 checkpoint) ---\n",
    "\n",
    "meta = {\n",
    "    \"tag\": OUT_TAG,\n",
    "    \"distill_cfg\": {\n",
    "        \"N_DISTILL_POSITIONS\": int(N_DISTILL_POSITIONS),\n",
    "        \"USE_MENTOR\": bool(USE_MENTOR),\n",
    "        \"MENTOR_DEPTH\": int(MENTOR_DEPTH),\n",
    "        \"MENTOR_PROB\": float(MENTOR_PROB),\n",
    "        \"MENTOR_COEF\": float(MENTOR_COEF),\n",
    "        \"MENTOR_MIN_CONF\": float(MENTOR_MIN_CONF),\n",
    "        \"LR\": float(LR),\n",
    "        \"WEIGHT_DECAY\": float(WEIGHT_DECAY),\n",
    "        \"EPOCHS\": int(EPOCHS),\n",
    "        \"BATCH_SIZE\": int(BATCH_SIZE),\n",
    "    },\n",
    "}\n",
    "\n",
    "save_cnet192(\n",
    "    path=OUT_PATH,\n",
    "    model=student,\n",
    "    cfg={\"input_channels\": 1, \"use_mid_3x3\": bool(getattr(student, \"use_mid_3x3\", True))},\n",
    "    **meta,\n",
    ")\n",
    "\n",
    "print(\"Saved:\", OUT_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9242eb65-ed18-40e3-9d52-6d9ca9e521d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
