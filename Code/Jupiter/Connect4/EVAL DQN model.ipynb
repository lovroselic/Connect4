{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dc1db620-d548-4056-b511-e9ac63c7dc6c",
   "metadata": {},
   "source": [
    "# Evaluate DQN model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dd5dd4e-2529-4d7c-9e38-7bef1135eff8",
   "metadata": {},
   "source": [
    "## Import dependecies and recheck installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b768e305-7069-4d06-9530-a2d5617560eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All dependencies imported successfully.\n",
      "torch version: 2.5.1\n",
      "CUDA available: True\n",
      "CUDA version: 11.8\n",
      "GPU name: NVIDIA GeForce RTX 4090\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchinfo import summary\n",
    "import numpy as np\n",
    "import random\n",
    "from collections import deque\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "import time\n",
    "import pprint;\n",
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "from copy import deepcopy\n",
    "from collections import deque\n",
    "from IPython.display import display, clear_output, HTML\n",
    "\n",
    "print(\"All dependencies imported successfully.\")\n",
    "print(\"torch version:\", torch.__version__)\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"CUDA version:\", torch.version.cuda)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU name:\", torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    print(\"CUDA not available. Using CPU. Why????\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eced052f-8ccc-4e0f-a8cd-dcf6c27a7446",
   "metadata": {},
   "source": [
    "### Fixed Random seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b36059b-73c8-4356-ba7a-037473dca494",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 666\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "os.environ[\"PYTHONHASHSEED\"] = str(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4653a09a-6263-4cdf-ad4d-ca960a72645c",
   "metadata": {},
   "outputs": [],
   "source": [
    "LOG_DIR =\"Logs/DQN/\"\n",
    "MODEL_DIR =\"Models/DQN/\"\n",
    "PLOTS = \"Plots/DQN/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce9f9655-bbba-4950-9260-548b64261ac9",
   "metadata": {},
   "source": [
    "## My imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "92b037ed-2332-4851-ae94-945d511deeba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All custom ependencies imported successfully.\n"
     ]
    }
   ],
   "source": [
    "from C4.connect4_env import Connect4Env\n",
    "from C4.fast_connect4_lookahead import Connect4Lookahead\n",
    "from DQN.DQN_replay_memory_per import PrioritizedReplayMemory\n",
    "from DQN.dqn_model import DQN\n",
    "from DQN.dqn_agent import DQNAgent\n",
    "from DQN.dqn_utilities import *\n",
    "from DQN.eval_utilities import evaluate_agent_model, log_phase_evaluation, sanity_check_random_vs_random\n",
    "from C4.connect4_board_display import display_final_boards\n",
    "from C4.eval_oppo_dict import EVALUATION_OPPONENTS\n",
    "\n",
    "Lookahead = Connect4Lookahead()\n",
    "\n",
    "print(\"All custom ependencies imported successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "84eb8661-d4cf-4cce-a79f-9100c87e6778",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started evaluation session EVAL - RANDOM I--at-2025-10-25 11-29-38\n"
     ]
    }
   ],
   "source": [
    "model_name = \"RANDOM I\"      # evaluating\n",
    "\n",
    "tag = f\"EVAL - {model_name}\"\n",
    "begin_start_time = time.time()\n",
    "time_str = time.strftime('%Y-%m-%d %H-%M-%S', time.localtime(begin_start_time))\n",
    "TRAINING_SESSION = f\"{tag}--at-{time_str}\"\n",
    "\n",
    "print(\"Started evaluation session\", TRAINING_SESSION)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85828dad-898a-4e57-b167-1a7755a4e855",
   "metadata": {},
   "source": [
    "#### Loading checkpoint model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a3f3c5f2-7346-4d62-b666-0eb10c679738",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"using device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "341ed919-650d-42ed-9544-7382481397bb",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'RANDOM I DQN model.pt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m agent \u001b[38;5;241m=\u001b[39m DQNAgent(device\u001b[38;5;241m=\u001b[39mdevice)  \u001b[38;5;66;03m# Fresh agent \u001b[39;00m\n\u001b[0;32m      3\u001b[0m model_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m DQN model.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 4\u001b[0m state_dict \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m agent\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mload_state_dict(state_dict)\n\u001b[0;32m      6\u001b[0m agent\u001b[38;5;241m.\u001b[39mupdate_target_model()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dqn-gpu\\lib\\site-packages\\torch\\serialization.py:1319\u001b[0m, in \u001b[0;36mload\u001b[1;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[0;32m   1316\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m   1317\u001b[0m     pickle_load_args[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1319\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[0;32m   1320\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[0;32m   1321\u001b[0m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[0;32m   1322\u001b[0m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[0;32m   1323\u001b[0m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[0;32m   1324\u001b[0m         orig_position \u001b[38;5;241m=\u001b[39m opened_file\u001b[38;5;241m.\u001b[39mtell()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dqn-gpu\\lib\\site-packages\\torch\\serialization.py:659\u001b[0m, in \u001b[0;36m_open_file_like\u001b[1;34m(name_or_buffer, mode)\u001b[0m\n\u001b[0;32m    657\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[0;32m    658\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[1;32m--> 659\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    660\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    661\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dqn-gpu\\lib\\site-packages\\torch\\serialization.py:640\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[1;34m(self, name, mode)\u001b[0m\n\u001b[0;32m    639\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, mode):\n\u001b[1;32m--> 640\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'RANDOM I DQN model.pt'"
     ]
    }
   ],
   "source": [
    "env = Connect4Env()\n",
    "agent = DQNAgent(device=device)  # Fresh agent \n",
    "model_name=f\"{model_name} DQN model.pt\"\n",
    "state_dict = torch.load(model_name, map_location=device, weights_only=True)\n",
    "agent.model.load_state_dict(state_dict)\n",
    "agent.update_target_model()\n",
    "agent.epsilon = 0.0  \n",
    "print(f\"✅ {model_name} loaded and ready for further training.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31153e6e-79a6-4106-af92-b6cac6b6f834",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d19fc2-d5ed-4dcf-bb41-2d471a746d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "sanity_check_random_vs_random(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb37c78-44b6-47d8-8fc3-75b12780f721",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Pure-model evaluation ===\n",
    "env.reset()\n",
    "DEBUG = False\n",
    "debug_depth = 1\n",
    "evaluation_results = evaluate_agent_model(agent, env, EVALUATION_OPPONENTS, device, Lookahead, debug=DEBUG, debug_depth=debug_depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "016fd424-c11f-48d9-b7a7-68f8285e556e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Print Summary ===\n",
    "print(\"\\n📊 Evaluation Summary:\")\n",
    "for label, stats in evaluation_results.items():\n",
    "    print(f\"{label}: {stats['wins']}W / {stats['losses']}L / {stats['draws']}D → \"\n",
    "          f\"Win: {stats['win_rate']*100:.1f}%, Loss: {stats['loss_rate']*100:.1f}%, Draw: {stats['draw_rate']*100:.1f}%\")\n",
    "\n",
    "# === Bar Plot Summary ===\n",
    "labels = list(evaluation_results.keys())\n",
    "win_rates  = [evaluation_results[k]['win_rate']  * 100 for k in labels]\n",
    "loss_rates = [evaluation_results[k]['loss_rate'] * 100 for k in labels]\n",
    "draw_rates = [evaluation_results[k]['draw_rate'] * 100 for k in labels]\n",
    "\n",
    "x = range(len(labels))\n",
    "bar_width = 0.25\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(x, win_rates, width=bar_width, label='Win %')\n",
    "plt.bar([i + bar_width for i in x], loss_rates, width=bar_width, label='Loss %')\n",
    "plt.bar([i + 2 * bar_width for i in x], draw_rates, width=bar_width, label='Draw %')\n",
    "plt.xlabel('Opponent Type')\n",
    "plt.ylabel('Percentage')\n",
    "plt.title('DQN Agent Performance vs Various Opponents')\n",
    "plt.xticks([i + bar_width for i in x], labels, rotation=15)\n",
    "plt.legend()\n",
    "plt.grid(True, linestyle='--', alpha=0.6)\n",
    "plt.tight_layout()\n",
    "\n",
    "plot_path = f\"{PLOTS}DQN-{TRAINING_SESSION}-evaluation_plot.png\"\n",
    "plt.savefig(plot_path, dpi=150)\n",
    "print(f\"📊 Plot saved to {plot_path}\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Save results\n",
    "df_eval = pd.DataFrame.from_dict(evaluation_results, orient='index')\n",
    "df_eval.index.name = \"Opponent\"\n",
    "# Use Excel if available; otherwise fall back to CSV\n",
    "try:\n",
    "    df_eval.to_excel(f\"{LOG_DIR}DQN-{TRAINING_SESSION}-evaluation_results.xlsx\", index=True)\n",
    "except Exception as e:\n",
    "    print(\"Excel export failed, saving CSV instead:\", e)\n",
    "    df_eval.to_csv(f\"{LOG_DIR}DQN-{TRAINING_SESSION}-evaluation_results.csv\", index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c8eed9f-9916-4613-8fe1-98596a11bde3",
   "metadata": {},
   "source": [
    "### Boards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ed55aa-1a0c-43e4-b339-ef5bb74e169b",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_final_boards(agent, env, device, Lookahead, [\"Random\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "001842bd-fc61-4643-b767-0125a1a7bd4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_final_boards(agent, env, device, Lookahead, [\"Lookahead-1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa71f6ca-5a7d-41db-a674-b2ce9e17efc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_final_boards(agent, env, device, Lookahead, [\"Lookahead-2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e0664e-3f27-46b0-986e-fdba1619e809",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_final_boards(agent, env, device, Lookahead, [\"Lookahead-3\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f052e79a-89cd-4249-9f15-792227cd2c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_final_boards(agent, env, device, Lookahead, [\"Lookahead-4\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55b01784-2970-4c87-a91b-ca40a635ab0d",
   "metadata": {},
   "source": [
    "# DONE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cabf946-a47a-427e-8aa9-ccc9c844a6ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_end_time = time.time()\n",
    "total_elapsed = (total_end_time - begin_start_time) / 3600\n",
    "print(f\"Evaluation completed in {total_elapsed:.1f} hours\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f8e8d05-4a25-47b9-afb9-aea190a1f90e",
   "metadata": {},
   "source": [
    "## Training log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0601c437-841c-459f-93d4-029cdfa9dc43",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TRAINING_SESSION\n",
    "if not DEBUG:\n",
    "    training_log_file = \"DQN training_sessions.xlsx\"\n",
    "    log_row = {\"TRAINING_SESSION\": TRAINING_SESSION, \"TIME [h]\": total_elapsed, \"EPISODES\": 0}\n",
    "    \n",
    "    for label, stats in evaluation_results.items():\n",
    "        log_row[label] = stats[\"win_rate\"]\n",
    "    \n",
    "    # === Load or Create Excel File ===\n",
    "    if os.path.exists(training_log_file):\n",
    "        df_log = pd.read_excel(training_log_file)\n",
    "    else:\n",
    "        df_log = pd.DataFrame()\n",
    "    \n",
    "    # === Append and Save ===\n",
    "    df_log = pd.concat([df_log, pd.DataFrame([log_row])], ignore_index=True)\n",
    "    df_log.to_excel(training_log_file, index=False)\n",
    "    \n",
    "    print(f\"\\n📁 Training session logged to: {training_log_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "305a2ddc-ff98-4036-ac51-9562c1c92769",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
